{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d67234",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">  Student Information</span>\n",
    "***\n",
    "Surname: **Zhang**  <br/>\n",
    "Firstname: **Yiming**    <br/>\n",
    "Student ID: **35224436**    <br/>\n",
    "Email: **yzha1213@student.monash.edu**    <br/>\n",
    "Your tutorial time: **Wed 12pm**    <br/>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a65c25",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Part 2: Deep Neural Networks (DNN) </span>\n",
    "<div style=\"text-align: right\"><span style=\"color:red; font-weight:bold\">[Total marks for this part: 25 points]<span></div>\n",
    "\n",
    "The second part of this assignment is to demonstrate your basis knowledge in deep learning that you have acquired from the lectures and tutorials materials. Most of the contents in this assignment are drawn from **the tutorials covered from weeks 1 to 2**. Going through these materials before attempting this assignment is highly recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd76975",
   "metadata": {},
   "source": [
    "In the second part of this assignment, you are going to work with the FashionMNIST dataset for the image recognition task. It has the exact same format as MNIST (70,000 grayscale images of 28 × 28 pixels each with 10 classes), but the images represent fashion items rather than handwritten digits, so each class is more diverse, and the problem is significantly more challenging than MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e718e2b",
   "metadata": {},
   "source": [
    "**Load the Fashion MNIST using `torchvision`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30660e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset_orgin = datasets.FashionMNIST(root='./data', train=True, download=False, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=False, transform=transform)\n",
    "\n",
    "print(train_dataset_orgin.data.shape, train_dataset_orgin.targets.shape)\n",
    "print(test_dataset.data.shape, test_dataset.targets.shape)\n",
    "\n",
    "# Flatten the data\n",
    "train_dataset_orgin.data = train_dataset_orgin.data.reshape(-1, 28*28)\n",
    "test_dataset.data = test_dataset.data.reshape(-1, 28*28)\n",
    "\n",
    "print(train_dataset_orgin.data.shape, train_dataset_orgin.targets.shape)\n",
    "print(test_dataset.data.shape, test_dataset.targets.shape)\n",
    "\n",
    "N = len(train_dataset_orgin)\n",
    "print(f\"Number of training samples: {N}\")\n",
    "N_train = int(0.9*N)\n",
    "N_val = N - N_train\n",
    "print(f\"Number of training samples: {N_train}\")\n",
    "print(f\"Number of validation samples: {N_val}\")\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset_orgin, [N_train, N_val])\n",
    "\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94102335",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 2.1:**</span> Write the code to visualize a mini-batch in `train_loader` including its images and labels.\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94855678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize_images(loader, batch_size=64):\n",
    "    \"\"\"\n",
    "    Visualize the images in the loader\n",
    "    batch_size: the number of images to show\n",
    "    \"\"\"\n",
    "    images, labels = next(iter(loader))\n",
    "\n",
    "    cols = int(batch_size**0.5)\n",
    "    rows = (batch_size + cols - 1) // cols\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for idx in range(min(batch_size, len(images))):\n",
    "        plt.subplot(rows, cols, idx + 1)\n",
    "        # reshape the image to 28x28\n",
    "        image = images[idx].detach().numpy().reshape(28, 28)\n",
    "        plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
    "        plt.title(f\"Class: {labels[idx].item()}\", fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Visualization ofFashion-MNIST\", fontsize=14, y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_images(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e65bd",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">**Question 2.2:**</span> Write the code for the feed-forward neural net using PyTorch\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b41d4b",
   "metadata": {},
   "source": [
    "We now develop a feed-forward neural network with the architecture $784 \\rightarrow 40(ReLU) \\rightarrow 30(ReLU) \\rightarrow 10(softmax)$. You can choose your own way to implement your network and an optimizer of interest. You should train model in $50$ epochs and evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f53e92d",
   "metadata": {},
   "source": [
    "##### FFN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7109147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "# ===== Model =====\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FFN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 40)\n",
    "        self.fc2 = nn.Linear(40, 30)\n",
    "        self.fc3 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten the image to 28*28\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        logits = F.softmax(self.fc3(x), dim=1) # (B, 10)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec57ad56",
   "metadata": {},
   "source": [
    "##### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f9506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FFN().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e6199a",
   "metadata": {},
   "source": [
    "##### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdce48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # cross entropy loss\n",
    "optimizer = Adam(model.parameters(), lr=1e-3) # Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d32d16",
   "metadata": {},
   "source": [
    "##### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf77bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, loader, train=True, criterion=None, optimizer=None):\n",
    "    model.train(mode=train)\n",
    "    total_loss, total_correct, total_samp = 0.0, 0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        if train:  # only update the model parameters when training\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total_samp += images.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samp\n",
    "    acc = total_correct / total_samp\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad2447c",
   "metadata": {},
   "source": [
    "##### Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f916df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Training loop (50 epochs) =====\n",
    "print(\"Training...\\n\")\n",
    "EPOCHS = 50\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = run_epoch(\n",
    "        model, train_loader, train=True, criterion=criterion, optimizer=optimizer\n",
    "    )\n",
    "    valid_loss, valid_acc = run_epoch(\n",
    "        model, val_loader, train=False, criterion=criterion, optimizer=optimizer\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{EPOCHS}, \"\n",
    "        f\"Train loss {train_loss:.4f} acc {(train_acc*100):.2f}%, \"\n",
    "        f\"Valid loss {valid_loss:.4f} acc {(valid_acc*100):.2f}%\"\n",
    "    )\n",
    "print(\"Training done!\")\n",
    "# Test the model with test set\n",
    "print(f\"\\nTesting Result:\")\n",
    "test_loss, test_acc = run_epoch(\n",
    "    model,\n",
    "    test_loader,\n",
    "    train=False,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    ")\n",
    "print(f\"Test loss: {test_loss:.4f}, Valid acc: {(test_acc*100):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d6e2f3",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 2.3:**</span> Tuning hyper-parameters with grid search\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b55b69",
   "metadata": {},
   "source": [
    "Assume that you need to tune the number of neurons on the first and second hidden layers $n_1 \\in \\{20, 40\\}$, $n_2 \\in \\{20, 40\\}$  and the used activation function  $act \\in \\{sigmoid, tanh, relu\\}$. The network has the architecture pattern $784 \\rightarrow n_1 (act) \\rightarrow n_2(act) \\rightarrow 10(softmax)$ where $n_1, n_2$, and $act$ are in their grides. Write the code to tune the hyper-parameters $n_1, n_2$, and $act$. Note that you can freely choose the optimizer and learning rate of interest for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8796449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "class tunable_FFN(nn.Module):\n",
    "    \"\"\"FNN can be tuned by changing the number of neurons and the activation function\"\"\"\n",
    "\n",
    "    def __init__(self, n1, n2, act):\n",
    "        super(tunable_FFN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, n1)\n",
    "        self.fc2 = nn.Linear(n1, n2)\n",
    "        self.fc3 = nn.Linear(n2, 10)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten the image to 28*28\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        logits = F.softmax(self.fc3(x), dim=1)  # (B, 10)\n",
    "        return logits\n",
    "\n",
    "\n",
    "EPOCHS_TUNE = 50\n",
    "# store the results of each hyper-parameter combination (n1, n2, act, valid_loss, valid_acc, test_loss, test_acc)\n",
    "results = []\n",
    "best_config = None  # store the best config for question 2.5\n",
    "\n",
    "\n",
    "def train_on_epoch(model, loader, criterion, optimizer, train=True):\n",
    "    \"\"\"Train the model for each epoch\"\"\"\n",
    "    model.train(mode=train)\n",
    "    loss_epoch, acc_epoch, samp_epoch = 0.0, 0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item() * images.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        acc_epoch += (preds == labels).sum().item()\n",
    "        samp_epoch += images.size(0)\n",
    "\n",
    "    train_loss_epoch = loss_epoch / samp_epoch  # loss of the epoch\n",
    "    train_acc_epoch = acc_epoch / samp_epoch  # accuracy of the epoch\n",
    "    return train_loss_epoch, train_acc_epoch\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer):\n",
    "    \"\"\"Train the model with different hyper-parameters\"\"\"\n",
    "    for epoch in range(1, EPOCHS_TUNE + 1):\n",
    "        train_loss, train_acc = train_on_epoch(\n",
    "            model, train_loader, criterion, optimizer, train=True\n",
    "        )\n",
    "        valid_loss, valid_acc = train_on_epoch(\n",
    "            model, test_loader, criterion, optimizer, train=False\n",
    "        )\n",
    "        print(\n",
    "            f\"Epoch {epoch}/{EPOCHS_TUNE}, \"\n",
    "            f\"Train loss {train_loss:.4f} acc {(train_acc*100):.2f}%, \"\n",
    "            f\"Valid loss {valid_loss:.4f} acc {(valid_acc*100):.2f}%\"\n",
    "        )\n",
    "\n",
    "    return valid_loss, valid_acc\n",
    "\n",
    "\n",
    "def evaluate(model=None):\n",
    "    \"\"\"test the model on the test set\"\"\"\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss, test_acc = train_on_epoch(\n",
    "        model, test_loader, criterion, optimizer, train=False\n",
    "    )\n",
    "    print(f\"test_loss={test_loss:.4f}, test_acc={(test_acc*100):.2f}%\")\n",
    "    return test_loss, test_acc\n",
    "\n",
    "\n",
    "def fine_tune():\n",
    "    global best_config, results\n",
    "    \"\"\"Fine-tune the model with different hyper-parameters\"\"\"\n",
    "    n1_grid = [20, 40]\n",
    "    n2_grid = [20, 40]\n",
    "    act_grid = [F.sigmoid, F.tanh, F.relu]\n",
    "    print(\"Start tuning...\")\n",
    "    for n1 in n1_grid:\n",
    "        for n2 in n2_grid:\n",
    "            for act in act_grid:\n",
    "                print(f\"\\n[Config] n1 = {n1}, n2 = {n2}, act = {act.__name__}\")\n",
    "                model = tunable_FFN(n1, n2, act).to(device)\n",
    "                optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                valid_loss, valid_acc = train_model(model, criterion, optimizer)\n",
    "                test_loss, test_acc = evaluate(model)\n",
    "                results.append(\n",
    "                    (n1, n2, act, valid_loss, valid_acc, test_loss, test_acc)\n",
    "                )\n",
    "    print(\"Tuning done!\")\n",
    "\n",
    "    # find the best config and model by max test_acc\n",
    "    best_config = max(results, key=lambda x: x[6])\n",
    "    n1, n2, act, _, _, _, best_acc = best_config\n",
    "    print(\n",
    "        f\"Best config:\",\n",
    "        f\"\\nNetwork architecture: 784 -> {n1} -> {n2} -> 10\",\n",
    "        f\"\\nActivation function: {act.__name__}\",\n",
    "        f\"\\nBest accuracy: {best_acc*100:.2f}%\",\n",
    "    )\n",
    "\n",
    "\n",
    "fine_tune()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f0222",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 2.4:**</span> Implement the loss with the form: $loss(p,y)=CE(1_{y},p)+\\lambda H(p)$ where $H(p)=-\\sum_{i=1}^{M}p_{i}\\log p_{i}$ is the entropy of $p$, $p$ is the prediction probabilities of a data point $x$ with the ground-truth label $y$, $1_y$ is an one-hot label, and $\\lambda >0$ is a trade-off parameter. Set $\\lambda = 0.1$ to train a model.\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4def064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CEWithRegularization(nn.Module):\n",
    "    \"\"\"CE with regularization item.\"\"\"\n",
    "\n",
    "    def __init__(self, lam=0.1):\n",
    "        super(CEWithRegularization, self).__init__()\n",
    "        self.lam = lam\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce = self.ce(logits, targets)\n",
    "        p = F.softmax(logits, dim=1)  # convert logits to probability\n",
    "        epsilon = 1e-12  # avoid log(0)\n",
    "        entropy = -(p * (p + epsilon).log()).sum(dim=1).mean()  # average over batch\n",
    "\n",
    "        return ce + self.lam * entropy  # total loss\n",
    "\n",
    "\n",
    "class FFN_CER(nn.Module):\n",
    "    \"\"\"FFN with CE with regularization.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FFN_CER, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 40)\n",
    "        self.fc2 = nn.Linear(40, 30)\n",
    "        self.fc3 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eb68e0",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a62e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFN_CER()\n",
    "criterion = CEWithRegularization()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "print(\"Start training with CE with regularization..\\n\")\n",
    "\n",
    "# training model\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "\n",
    "    mean_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # validation\n",
    "    model.eval() # Set model to eval mode for inference\n",
    "    total_correct = 0\n",
    "    total_samp = 0\n",
    "    with torch.no_grad(): # No need to track gradients for validation\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = model(images)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_samp += labels.size(0)\n",
    "    val_acc = total_correct / total_samp\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{EPOCHS}, Train loss {mean_loss:.4f}, Valid acc {(val_acc*100):.2f}%\"\n",
    "    )\n",
    "\n",
    "\n",
    "# test model\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samp = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        logits = model(images)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total_samp += labels.size(0)\n",
    "test_acc = total_correct / total_samp\n",
    "print(f\"Test acc: {(test_acc*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c88317f",
   "metadata": {},
   "source": [
    "####  <span style=\"color:red\">**Question 2.5:**</span> Experimenting with **sharpness-aware minimization** technique\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>\n",
    "\n",
    "Sharpness-aware minimization (SAM) (i.e., [link for main paper](https://openreview.net/pdf?id=6Tm1mposlrM) from Google Deepmind) is a simple yet but efficient technique to improve the generalization ability of deep learning models on unseen data examples. In your research or your work, you might potentially use this idea. Your task is to read the paper and implement *Sharpness-aware minimization (SAM)*. Finally, you need to apply SAM to the best architecture found in **Question 2.3**.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "class SAM_optimizer(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n",
    "        # kwargs 里放 base optimizer 的超参，如 lr/momentum/weight_decay\n",
    "        defaults = dict(rho=rho, **kwargs)\n",
    "        super().__init__(params, defaults)\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.rho = rho\n",
    "\n",
    "    def grad_norm(self):\n",
    "        device = self.param_groups[0][\"params\"][0].device\n",
    "        norms = []\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad\n",
    "                norms.append(grad.norm(p=2))\n",
    "        return torch.norm(torch.stack(norms), p=2).to(device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=True):\n",
    "        scale = self.rho / (self.grad_norm() + 1e-12)\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                e = p.grad\n",
    "                e = e * scale\n",
    "                p.add_(e)  # w <- w + e\n",
    "                self.state[p][\"e_w\"] = e  # store the perturbation\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=True):\n",
    "        \"\"\"recover the parameters\"\"\"\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if \"e_w\" in self.state[p]:\n",
    "                    p.sub_(self.state[p][\"e_w\"])  # w <- w - e\n",
    "        self.base_optimizer.step()  # update the model\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.base_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f1b4a",
   "metadata": {},
   "source": [
    "##### Test with best config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c5098",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN_best(nn.Module):\n",
    "    def __init__(self, n1, n2, act):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, n1)\n",
    "        self.fc2 = nn.Linear(n1, n2)\n",
    "        self.fc3 = nn.Linear(n2, 10)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.act(self.fc2(x))\n",
    "        return self.fc3(x)  # logits\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load the parameters from the best config\n",
    "print(\"Best config:\", best_config)\n",
    "n1, n2, act, _, _, _, _ = best_config\n",
    "model = FFN_best(n1, n2, act).to(device)\n",
    "print(\"Best model:\", model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "sam = SAM_optimizer(\n",
    "    model.parameters(),\n",
    "    base_optimizer=torch.optim.SGD,\n",
    "    rho=0.05,\n",
    "    lr=0.01,\n",
    ")\n",
    "\n",
    "\n",
    "def train_one_epoch(loader):\n",
    "    model.train()\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # step 1\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        sam.first_step(zero_grad=True)\n",
    "\n",
    "        # step 2\n",
    "        logits_perturbed = model(images)\n",
    "        loss_perturbed = criterion(logits_perturbed, labels)\n",
    "        loss_perturbed.backward()\n",
    "        sam.second_step(zero_grad=True)\n",
    "\n",
    "        # statistics\n",
    "        total += images.size(0)\n",
    "        correct += logits.argmax(1).eq(labels).sum().item()\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        total += images.size(0)\n",
    "        correct += logits.argmax(1).eq(labels).sum().item()\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "# training loop\n",
    "print(\"Training with SAM...\\n\")\n",
    "EPOCHS_SAM = 20\n",
    "for ep in range(1, EPOCHS_SAM + 1):\n",
    "    tr_loss, tr_acc = train_one_epoch(train_loader)\n",
    "    va_loss, va_acc = evaluate(val_loader)\n",
    "    print(\n",
    "        f\"Epoch {ep:02d}/{EPOCHS_SAM}, Train loss {tr_loss:.4f} acc {(tr_acc*100):.2f}%, Val loss {va_loss:.4f} acc {(va_acc*100):.2f}%\"\n",
    "    )\n",
    "print(\"\\nTraining with SAM done!\")\n",
    "\n",
    "# test model\n",
    "test_loss, test_acc = evaluate(test_loader)\n",
    "print(\n",
    "    f\"\\nTest results with SAM -> Test loss: {test_loss:.4f}, Test acc: {(test_acc*100):.2f}%\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
